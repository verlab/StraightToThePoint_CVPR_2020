{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "if \"../\" not in sys.path: sys.path.append(\"../\")\n",
    "import cv2\n",
    "from utils import load_checkpoint, convert_sentences_to_word_idxs\n",
    "from experiment_to_video_mapping import Experiment2VideoMapping\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime\n",
    "from extract_vdan_feats import extract_feats, colorize\n",
    "from IPython.core.display import HTML\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision.transforms as T\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "%matplotlib notebook\n",
    "from ipywidgets import *\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "cudnn.benchmark = True\n",
    "\n",
    "IMAGENET_MEAN   = [0.485, 0.456, 0.406]\n",
    "IMAGENET_STD    = [0.229, 0.224, 0.225]\n",
    "\n",
    "img_transform = T.Compose( [T.Resize((224,224)),\n",
    "                            T.ToTensor(),\n",
    "                            T.Normalize(mean=IMAGENET_MEAN, std=IMAGENET_STD)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please select the model and click 'Run Interact'\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6476a91fc1f490a9812bda142f4ebec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='model_filename', options=('README', 'vdan_model_dict.pth', '202012â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Please select the model and click 'Run Interact'\")\n",
    "\n",
    "@interact_manual\n",
    "def select_model(model_filename=os.listdir('../models/')):\n",
    "    print('[{}] Loading saved model weights...'.format(datetime.now().strftime('%Y-%m-%d %H:%M:%S')))\n",
    "    _, model, optimizer_state_dict, word_map, model_params, train_params = load_checkpoint('../models/{}'.format(model_filename))\n",
    "    model.to(device)\n",
    "    print('[{}] Done!\\n'.format(datetime.now().strftime('%Y-%m-%d %H:%M:%S')))\n",
    "    # SET THE EXPERIMENT ID\n",
    "    # Create widgets\n",
    "    datasets = widgets.Dropdown(options=['YouCook2'])\n",
    "    experiments = widgets.Dropdown(options=Experiment2VideoMapping.get_dataset_experiments(datasets.value))\n",
    "\n",
    "    # Updates the experiment options based on dataset value\n",
    "    def update_experiments(*args):\n",
    "        experiments.options = Experiment2VideoMapping.get_dataset_experiments(datasets.value)\n",
    "\n",
    "    # Tie the experiment options to dataset value\n",
    "    datasets.observe(update_experiments, 'value')\n",
    "\n",
    "    # Define the experiment\n",
    "    def define_experiment(dataset, experiment):\n",
    "        exp_map = Experiment2VideoMapping(experiment)\n",
    "\n",
    "        video = cv2.VideoCapture(exp_map.video_filename)\n",
    "        num_frames = int(video.get(7))\n",
    "\n",
    "        @interact\n",
    "        def show_articles_more_than(frame_id=(0, num_frames-1)):\n",
    "            video.set(1, frame_id)\n",
    "            ret, frame = video.read()\n",
    "\n",
    "            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "            frame = Image.fromarray(frame)\n",
    "            img = img_transform(frame)\n",
    "            document = np.loadtxt(exp_map.user_document_filename, delimiter='\\n', dtype=str, encoding='utf-8')\n",
    "\n",
    "            img_feats, document_feats, word_alphas, sentence_alphas = extract_feats(model, word_map, train_params['max_words'], imgs=img.unsqueeze(0), docs=[document])\n",
    "\n",
    "            #pdb.set_trace()\n",
    "            s = []\n",
    "            for i, sentence in enumerate(document):\n",
    "                words_color_array = word_alphas.cpu().detach().numpy()[0][i] if word_alphas is not None else np.array([1.]*len(sentence))\n",
    "                sents_color_array = sentence_alphas.cpu().detach().numpy()[0]    \n",
    "                words = sentence.split()\n",
    "                s.append(colorize(words, words_color_array, sents_color_array, i))\n",
    "\n",
    "            img_feats = img_feats.detach().cpu().numpy()[0]\n",
    "            document_feats = document_feats.detach().cpu().numpy()[0]\n",
    "\n",
    "            euc_dist = np.linalg.norm(img_feats - document_feats)\n",
    "            dot_product = np.dot(img_feats, document_feats.T)/(np.linalg.norm(img_feats)*np.linalg.norm(document_feats))\n",
    "\n",
    "            html_text = '<b>Euclidean Distance:</b> {:.3f}<br/><b>Cosine Similarity:</b> {:.3f}<br/><br/>'.format(euc_dist, dot_product)\n",
    "            for sentence in s:\n",
    "                html_text += sentence + '<br/>'\n",
    "            \n",
    "            display(frame.resize((224,224)))\n",
    "#             display(frame.resize((int(video.get(3)/2), int(video.get(4)/2))))\n",
    "            display(HTML(html_text))\n",
    "\n",
    "    _ = interact(define_experiment, dataset=datasets, experiment=experiments)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
